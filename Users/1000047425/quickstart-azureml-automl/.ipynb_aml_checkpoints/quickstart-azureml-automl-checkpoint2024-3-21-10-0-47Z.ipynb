{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/tutorials/quickstart-ci/ClassificationWithAutomatedML.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quickstart: Fraud Classification using Automated ML\n",
        "\n",
        "In this quickstart, you use automated machine learning in Azure Machine Learning service to  train a classification model on an associated fraud credit card dataset. This process accepts training data and configuration settings, and automatically iterates through combinations of different feature normalization/standardization methods, models, and hyperparameter settings to arrive at the best model.\n",
        "\n",
        "You will learn how to:\n",
        "\n",
        "> * Download a dataset and look at the data\n",
        "> * Train a machine learning classification model using autoML \n",
        "> * Explore the results\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to your workspace and create an experiment\n",
        "\n",
        "You start with importing some libraries and creating an experiment to track the runs in your workspace. A workspace can have multiple experiments, and all the users that have access to the workspace can collaborate on them. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.train.automl import AutoMLConfig"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1713692358900
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for your experiment\n",
        "experiment_name = \"fraud-classification-automl-tutorial\"\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1713692364028
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data\n",
        "\n",
        "Load the credit card dataset from a csv file containing both training features and labels. The features are inputs to the model, while the training labels represent the expected output of the model. Next, we'll split the data using random_split and extract the training data for the model.\n",
        "\n",
        "\n",
        "Follow this [how-to](https://aka.ms/azureml/howto/createdatasets) if you want to learn more about Datasets and how to use them.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/creditcard.csv\"\n",
        "dataset = Dataset.Tabular.from_delimited_files(data)\n",
        "training_data, validation_data = dataset.random_split(percentage=0.8, seed=223)\n",
        "label_column_name = \"Class\""
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1713692384157
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n",
        "\n",
        "\n",
        "When you use automated machine learning in Azure ML, you input training data and configuration settings, and the process automatically iterates through combinations of different feature normalization/standardization methods, models, and hyperparameter settings to arrive at the best model. \n",
        "Learn more about how you configure automated ML [here](https://docs.microsoft.com/azure/machine-learning/how-to-configure-auto-train).\n",
        "\n",
        "\n",
        "Instantiate an [AutoMLConfig](https://docs.microsoft.com/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py) object. This defines the settings and data used to run the experiment.\n",
        "\n",
        "|Property|Description|\n",
        "|-|-|\n",
        "|**task**|classification or regression|\n",
        "|**primary_metric**|This is the metric that you want to optimize. \n",
        "|**enable_early_stopping**  | Stop the run if the metric score is not showing improvement.|\n",
        "|**n_cross_validations**|Number of cross validation splits.|\n",
        "|**training_data**|Input dataset, containing both features and label column.|\n",
        "|**label_column_name**|The name of the label column.|\n",
        "\n",
        "You can find more information about primary metrics [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-auto-train#primary-metric)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_settings = {\n",
        "    \"n_cross_validations\": 3,\n",
        "    \"primary_metric\": \"average_precision_score_weighted\",\n",
        "    \"experiment_timeout_hours\": 0.75,  # This is a time limit for testing purposes, remove it for real use cases, this will drastically limit ability to find the best model possible\n",
        "    \"verbosity\": logging.INFO,\n",
        "    \"enable_stack_ensemble\": False,\n",
        "}\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    task=\"classification\",\n",
        "    debug_log=\"automl_errors.log\",\n",
        "    training_data=training_data,\n",
        "    label_column_name=label_column_name,\n",
        "    **automl_settings,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1713692391728
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the `submit` method on the experiment object and pass the run configuration. \n",
        "\n",
        "**Note: Depending on the data and the number of iterations an AutoML run can take a while to complete.**\n",
        "\n",
        "In this example, we specify `show_output = True` to print currently running iterations to the console. It is also possible to navigate to the experiment through the **Experiment** activity tab in the left menu, and monitor the run status from there."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_run = experiment.submit(automl_config, show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "No run_configuration provided, running on local with default configuration\nRunning in the active local environment.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fraud-classification-automl-tutorial</td><td>AutoML_c4bddb22-b767-4c8f-935c-b73536ba16a4</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_c4bddb22-b767-4c8f-935c-b73536ba16a4?wsid=/subscriptions/691cf246-8245-4c5a-b731-862a13af52f5/resourcegroups/hexamltest/workspaces/hexaaiml&amp;tid=7c0c36f5-af83-4c24-8844-9962e0163719\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current status: DatasetEvaluation. Gathering dataset statistics.\nCurrent status: FeaturesGeneration. Generating features for the dataset.\nCurrent status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\nCurrent status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\nCurrent status: DatasetBalancing. Performing class balancing sweeping\nCurrent status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Class balancing detection\nSTATUS:       ALERTED\nDESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\nDETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n+------------------------------+--------------------------------+--------------------------------------+\n|Size of the smallest class    |Name/Label of the smallest class|Number of samples in the training data|\n+==============================+================================+======================================+\n|396                           |True                            |227861                                |\n+------------------------------+--------------------------------+--------------------------------------+\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         High cardinality feature detection\nSTATUS:       PASSED\nDESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0   MaxAbsScaler LightGBM                          0:01:24             0.9967    0.9967\n    1   MaxAbsScaler XGBoostClassifier                 0:08:36             0.9997    0.9997\n    2   MaxAbsScaler ExtremeRandomTrees                0:01:23             0.9994    0.9997\n    3   SparseNormalizer XGBoostClassifier             0:01:43             0.9990    0.9997\n    4   MaxAbsScaler LightGBM                          0:01:10             0.9994    0.9997\n    5   VotingEnsemble                                 0:00:46             0.9996    0.9997\nStopping criteria reached at iteration 6. Ending experiment.\n********************************************************************************************\nCurrent status: BestRunExplainModel. Best run model explanations started\nCurrent status: ModelExplanationDataSetSetup. Model explanations data setup completed\nCurrent status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\nCurrent status: EngineeredFeatureExplanations. Computation of engineered features started\nCurrent status: EngineeredFeatureExplanations. Computation of engineered features completed\nCurrent status: RawFeaturesExplanations. Computation of raw features started\nCurrent status: RawFeaturesExplanations. Computation of raw features completed\nCurrent status: BestRunExplainModel. Best run model explanations completed\n********************************************************************************************\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024/04/21 09:42:41 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n2024-04-21:09:58:37,136 INFO     [explanation_client.py:334] Using default datastore for uploads\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1713693526902
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612976292559
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze results\n",
        "\n",
        "Below we select the best model from our iterations. The `get_output` method on `automl_classifier` returns the best run and the model for the run."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run, best_model = local_run.get_output()\n",
        "best_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612976298373
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tests\n",
        "\n",
        "Now that the model is trained, split the data in the same way the data was split for training (The difference here is the data is being split locally) and then run the test data through the trained model to get the predicted values."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the test data to dataframe\n",
        "X_test_df = validation_data.drop_columns(\n",
        "    columns=[label_column_name]\n",
        ").to_pandas_dataframe()\n",
        "y_test_df = validation_data.keep_columns(\n",
        "    columns=[label_column_name], validate=True\n",
        ").to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612976320370
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# call the predict functions on the model\n",
        "y_pred = best_model.predict(X_test_df)\n",
        "y_pred"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612976325829
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Calculate metrics for the prediction\n",
        "\n",
        "Now visualize the data to show what our truth (actual) values are compared to the predicted values \n",
        "from the trained model that was returned.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "cf = confusion_matrix(y_test_df.values, y_pred)\n",
        "plt.imshow(cf, cmap=plt.cm.Blues, interpolation=\"nearest\")\n",
        "plt.colorbar()\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "class_labels = [\"False\", \"True\"]\n",
        "tick_marks = np.arange(len(class_labels))\n",
        "plt.xticks(tick_marks, class_labels)\n",
        "plt.yticks([-0.5, 0, 1, 1.5], [\"\", \"False\", \"True\", \"\"])\n",
        "# plotting text value inside cells\n",
        "thresh = cf.max() / 2.0\n",
        "for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):\n",
        "    plt.text(\n",
        "        j,\n",
        "        i,\n",
        "        format(cf[i, j], \"d\"),\n",
        "        horizontalalignment=\"center\",\n",
        "        color=\"white\" if cf[i, j] > thresh else \"black\",\n",
        "    )\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612976330108
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Control cost and further exploration\n",
        "\n",
        "If you want to control cost you can stop the compute instance this notebook is running on by clicking the \"Stop compute\" button next to the status dropdown in the menu above.\n",
        "\n",
        "\n",
        "If you want to run more notebook samples, you can click on **Sample Notebooks** next to the **Files** view and explore the notebooks made available for you there."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "cewidste"
      }
    ],
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "notice": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License.",
    "categories": [
      "SDK v1",
      "tutorials",
      "compute-instance-quickstarts"
    ],
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}