{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from breeze_connect import BreezeConnect\n",
        "import json\n",
        "# Initialize SDK\n",
        "breeze = BreezeConnect(api_key=\"05l3(7895X4136976h@Za90m09681999\")\n",
        "\n",
        "# Generate Session\n",
        "breeze.generate_session(api_secret=\"516o05v3500859%I515F02eo#3l27876\",\n",
        "                        session_token=\"39608001\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1714363538201
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd \n",
        "import pyspark \n",
        "from pyspark.sql.functions import explode\n",
        "from pyspark.sql import SparkSession \n",
        "\n",
        "\n",
        "niftydata =json.dumps (breeze.get_quotes(stock_code=\"NIFTY\",\n",
        "                                          exchange_code=\"NSE\",\n",
        "                                          expiry_date=\"\",\n",
        "                                          product_type=\"cash\",\n",
        "                                          right=\"others\",\n",
        "                                          strike_price=\"0\"\n",
        "                                        )\n",
        "                       )\n",
        "\n",
        "spark = SparkSession.builder.appName('sparkdf').getOrCreate()                        \n",
        "sc = spark.sparkContext                       \n",
        "df = spark.read.json(sc.parallelize([niftydata])) \n",
        "\n",
        "flat_df = df.select(\"Error\",\"Status\",explode(\"Success\").alias(\"Success\"))\n",
        "flat_df =  flat_df.select (flat_df.Success.ltp.alias(\"now\"),\"Success.open\",\"Success.low\",\"Success.high\",flat_df.Success.previous_close.alias(\"lastdayclose\")).where(flat_df.Success.ltp > 0)  \n",
        "flat_df.show()                "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714363544205
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd \n",
        "import pyspark \n",
        "from pyspark.sql.functions import explode\n",
        "from pyspark.sql import SparkSession \n",
        "\n",
        "\n",
        "BankNifty =json.dumps (breeze.get_quotes(stock_code=\"CNXBAN\",\n",
        "                                          exchange_code=\"NSE\",\n",
        "                                          expiry_date=\"\",\n",
        "                                          product_type=\"cash\",\n",
        "                                          right=\"others\",\n",
        "                                          strike_price=\"0\"\n",
        "                                        )\n",
        "                       )\n",
        "\n",
        "spark = SparkSession.builder.appName('sparkdf').getOrCreate()                        \n",
        "sc = spark.sparkContext                       \n",
        "bndf = spark.read.json(sc.parallelize([BankNifty])) \n",
        "\n",
        "flat_bndf = bndf.select(\"Error\",\"Status\",explode(\"Success\").alias(\"Success\"))\n",
        "flat_bndf =  flat_bndf.select (flat_bndf.Success.ltp.alias(\"now\"),\"Success.open\",\"Success.low\",\"Success.high\",flat_bndf.Success.previous_close.alias(\"lastdayclose\")).where(flat_bndf.Success.ltp > 0)  \n",
        "flat_bndf.show()              "
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'Success'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m bndf \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mjson(sc\u001b[38;5;241m.\u001b[39mparallelize([BankNifty])) \n\u001b[1;32m     21\u001b[0m flat_bndf \u001b[38;5;241m=\u001b[39m bndf\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m,explode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 22\u001b[0m flat_bndf \u001b[38;5;241m=\u001b[39m  flat_bndf\u001b[38;5;241m.\u001b[39mselect (flat_bndf\u001b[38;5;241m.\u001b[39mSuccess\u001b[38;5;241m.\u001b[39mltp\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnow\u001b[39m\u001b[38;5;124m\"\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess.open\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess.low\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess.high\u001b[39m\u001b[38;5;124m\"\u001b[39m,flat_bndf\u001b[38;5;241m.\u001b[39mSuccess\u001b[38;5;241m.\u001b[39mprevious_close\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlastdayclose\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mflat_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSuccess\u001b[49m\u001b[38;5;241m.\u001b[39mltp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)  \n\u001b[1;32m     23\u001b[0m flat_bndf\u001b[38;5;241m.\u001b[39mshow()              \n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1988\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   1990\u001b[0m     )\n\u001b[1;32m   1991\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Success'"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714363600755
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd \n",
        "import pyspark \n",
        "from pyspark.sql.functions import explode\n",
        "import plotly.graph_objects as go\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType, MapType\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import subplots, draw\n",
        "from datetime import datetime\n",
        "  \n",
        "# importing sparksession from pyspark.sql module \n",
        "from pyspark.sql import SparkSession \n",
        "spark = SparkSession.builder.appName('sparkdf').getOrCreate() \n",
        "         \n",
        "niftydata =json.dumps (breeze.get_historical_data_v2(interval=\"1day\",\n",
        "                            from_date= \"2024-04-24T09:15:00.000Z\",\n",
        "                            to_date=   \"2024-04-29T13:30:30.000Z\",\n",
        "                            stock_code=\"NIFTY\",\n",
        "                            exchange_code=\"NSE\",\n",
        "                            product_type=\"cash\")\n",
        "                       )\n",
        "sc = spark.sparkContext                       \n",
        "df = spark.read.json(sc.parallelize([niftydata])) \n",
        "flat_df = df.select(\"Error\",\"Status\",explode(\"Success\").alias(\"Success\"))\n",
        "ohlc_df = flat_df.select(\"Success.datetime\",\"Success.open\",\"Success.low\",\"Success.high\",\"Success.close\")\n",
        "ohlc_df.show()\n",
        "row_count = ohlc_df.rdd.count()\n",
        "print(f'The DataFrame has {row_count} rows.')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1714363267213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "pandasDF = ohlc_df.toPandas()\n",
        "fig = go.Figure(data=[go.Candlestick(x=pandasDF['datetime'],\n",
        "                open=pandasDF['open'],\n",
        "                high=pandasDF['high'],\n",
        "                low=pandasDF['low'],\n",
        "                close=pandasDF['close'])])\n",
        "\n",
        "fig.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714363273210
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}